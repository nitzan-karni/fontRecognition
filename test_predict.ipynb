{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def characterCrop(img, charBB):\n",
    "    for i in range(4):\n",
    "        if charBB[0, i] < 0:\n",
    "            charBB[0, i] = 0\n",
    "        if charBB[1, i] < 0:\n",
    "            charBB[1, i] = 0\n",
    "        if charBB[0, i] > img.shape[1]:\n",
    "            charBB[0, i] = img.shape[1]\n",
    "        if charBB[1, i] > img.shape[0]:\n",
    "            charBB[1, i] = img.shape[0]\n",
    "            \n",
    "    pts = np.array(list((zip(charBB[0], charBB[1]))),dtype='int')\n",
    "    rect = cv2.boundingRect(pts)\n",
    "    x,y,w,h = rect\n",
    "    croped = img[y:y+h, x:x+w].copy()\n",
    "    pts = pts - pts.min(axis=0)\n",
    "    mask = np.zeros(croped.shape[:2], np.uint8)\n",
    "    cv2.drawContours(mask, [pts], -1, (255, 255, 255), -1, cv2.LINE_AA)\n",
    "    dst = cv2.bitwise_and(croped, croped, mask=mask)\n",
    "    bg = np.ones_like(croped, np.uint8)*255\n",
    "    cv2.bitwise_not(bg,bg, mask=mask)\n",
    "    dst2 = bg+ dst\n",
    "    dst2= np.where(dst2==(255,255,255), np.mean(croped, axis=(0,1), dtype=int).astype(np.uint8),dst2)\n",
    "    \n",
    "    return dst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDataset(file_name, test=False):\n",
    "    images = []\n",
    "    db = h5py.File(file_name, 'r')\n",
    "    im_names = list(db['data'].keys())\n",
    "    cShape = (32, 32)\n",
    "    wShape = (105, 105)\n",
    "    letters = set('a')\n",
    "    characterCount = 0\n",
    "    for im in im_names:\n",
    "        img = db['data'][im][:]\n",
    "        if not test:\n",
    "            font = db['data'][im].attrs['font']\n",
    "        txt = db['data'][im].attrs['txt']\n",
    "        charBB = db['data'][im].attrs['charBB']\n",
    "        wordBB = db['data'][im].attrs['wordBB']\n",
    "        charIndx = 0\n",
    "        \n",
    "        words = []\n",
    "        for i in range(0, len(txt)):\n",
    "            characters = []\n",
    "            for j in range(0, len(txt[i])):\n",
    "                o = characterCrop(img, charBB[:,:,charIndx])\n",
    "                if not 0 in o.shape:\n",
    "                    theta_horizontal = math.degrees(math.atan2(charBB[:,:,charIndx][1,2]-charBB[:,:,charIndx][1,3], charBB[:,:,charIndx][0,2]-charBB[:,:,charIndx][0,3]))\n",
    "                    #theta_horizontal = 0\n",
    "                    shear = 0\n",
    "                    if (charBB[:,:,charIndx][1,0]>charBB[:,:,charIndx][1,3]):\n",
    "                        shear = 180\n",
    "                        theta_horizontal=180+theta_horizontal\n",
    "                    aligned = tf.keras.preprocessing.image.apply_affine_transform(o, theta=-theta_horizontal, shear=shear)\n",
    "                    resized_aligned = cv2.resize(aligned, cShape)\n",
    "                    resized_aligned_gray = cv2.cvtColor(resized_aligned, cv2.COLOR_BGR2GRAY)\n",
    "                    \n",
    "                    if test:\n",
    "                        characters.append({ 'char_txt': txt[i][j:j+1].decode('UTF-8'),'croped': o, 'resized_aligned': resized_aligned_gray})\n",
    "                    else:\n",
    "                        characters.append({ 'char_txt': txt[i][j:j+1].decode('UTF-8'),'croped': o, 'resized_aligned': resized_aligned_gray, 'font': font[charIndx].decode('UTF-8')})\n",
    "                    characterCount +=1\n",
    "                charIndx += 1\n",
    "            wrd = txt[i].decode('UTF-8')\n",
    "            letters = letters.union(set(wrd))\n",
    "            wordImg = characterCrop(img, wordBB[:,:,i])\n",
    "            if not 0 in wordImg.shape:\n",
    "                wordImgRsz = cv2.resize(wordImg, wShape)\n",
    "            words.append({'wordBB': wordBB[:,:,i], 'txt':txt[i].decode('UTF-8'), 'characters': characters, 'word': wordImg, 'resized': wordImgRsz, 'charsCount': charIndx })\n",
    "            del characters\n",
    "        if test:\n",
    "            images.append({'img': img, 'txt': txt, 'words': words, 'im_name': im, 'wordBB': wordBB, 'charBB': charBB})\n",
    "        else:\n",
    "            images.append({'img': img, 'txt': txt, 'words': words, 'im_name': im, 'fonts': font, 'wordBB': wordBB, 'charBB': charBB})\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFonts(i):\n",
    "    \"\"\"\n",
    "    plot the fonts per character in the image\n",
    "    from the predictions\n",
    "    \n",
    "    Skylark - blue\n",
    "    Sweet Puppy - green\n",
    "    Ubuntu - red\n",
    "    \"\"\"\n",
    "    img = images[i]['img']\n",
    "    charBB = images[i]['charBB']\n",
    "    wordBB = images[i]['wordBB']\n",
    "    font_name = ['Skylark', 'Sweet Puppy', 'Ubuntu']\n",
    "    fonts = predictions[predictions['image'] == images[i]['im_name']][['Skylark', 'Sweet Puppy', 'Ubuntu Mono']]\n",
    "    fonts['index'] = list(range(0,len(fonts)))\n",
    "    fonts = fonts.set_index('index')\n",
    "    nC = charBB.shape[-1]\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.imshow(img)\n",
    "    for b_inx in range(nC):\n",
    "        if fonts.loc[b_inx]['Skylark'] == 1:\n",
    "            color = 'b'\n",
    "        elif fonts.loc[b_inx]['Sweet Puppy'] == 1:\n",
    "            color = 'g'\n",
    "        else:\n",
    "            color = 'r'\n",
    "        bb = charBB[:,:,b_inx]\n",
    "        x = np.append(bb[0,:], bb[0,0])\n",
    "        y = np.append(bb[1,:], bb[1,0])\n",
    "        plt.plot(x, y, color)\n",
    "    # plot the word's BB:\n",
    "    nW = wordBB.shape[-1]\n",
    "    for b_inx in range(nW):\n",
    "        bb = wordBB[:,:,b_inx]\n",
    "        x = np.append(bb[0,:], bb[0,0])\n",
    "        y = np.append(bb[1,:], bb[1,0])\n",
    "        plt.plot(x, y, 'k')\n",
    "    plt.title(\"blue - Skylark, green - Sweetpuppy, red - Ubuntu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def predictTestset(images_file, model, pathCSV='char_font_preds_project'):\n",
    "    \"\"\"\n",
    "    The procedure accepts dataset file in h5 format containing characters\n",
    "    The function creates excel with font prediction per character\n",
    "    using the following format\n",
    "    ROW - IMAGE NAME - CHARACTER - FONT BINARY PREDICTION 1X3\n",
    "    \"\"\"\n",
    "    images = readDataset(images_file, test=True)\n",
    "    chars = []\n",
    "    text = []\n",
    "    imgs_name = []\n",
    "    words = []\n",
    "    fontClasses = ['Ubuntu Mono', 'Skylark', 'Sweet Puppy']\n",
    "    for i in range(len(images)):\n",
    "        for w in range(len(images[i]['words'])):\n",
    "            for c in range(len(images[i]['words'][w]['characters'])):\n",
    "                text.append(images[i]['words'][w]['characters'][c]['char_txt'])\n",
    "                chars.append(images[i]['words'][w]['characters'][c]['resized_aligned'])\n",
    "                words.append(w)\n",
    "                imgs_name.append(images[i]['im_name'])\n",
    "    chars = np.array(chars)\n",
    "    text = np.array(text)\n",
    "    shapeT = chars.shape\n",
    "    chars_norm = chars.reshape(shapeT[0], shapeT[1], shapeT[2], 1)/255.0\n",
    "    predictions = model.predict(chars_norm)\n",
    "    \n",
    "    df = pd.DataFrame(predictions)\n",
    "    df = df.rename(columns={0: fontClasses[0], 1: fontClasses[1], 2: fontClasses[2]})\n",
    "    df['image'] = imgs_name\n",
    "    df['char'] = text\n",
    "    df['word'] = words\n",
    "    \n",
    "    vote = df.groupby(['image', 'word']).sum().idxmax(axis=1)\n",
    "    df['Skylark'] = 0\n",
    "    df['Sweet Puppy'] = 0\n",
    "    df['Ubuntu Mono'] = 0\n",
    "    \n",
    "    for i in range(0, len(df)):\n",
    "        r = df.loc[i]\n",
    "        df.loc[i, vote.loc[r['image'], r['word']]]=1\n",
    "    \n",
    "    df = df[['image', 'char', 'Skylark', 'Sweet Puppy', 'Ubuntu Mono']]\n",
    "    df.to_csv(path_or_buf=pathCSV)\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"CNN_font_original+val+added.h5\")\n",
    "path = 'test.h5'\n",
    "predictions = predictTestset(path, model, pathCSV='char_font_pred_test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotFonts(234)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
